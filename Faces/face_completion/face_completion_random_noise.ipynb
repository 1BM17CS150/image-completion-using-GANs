{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icarus/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time as ti\n",
    "import csv\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from pympler import asizeof\n",
    "import time as ti\n",
    "from PIL import Image\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "image_shape = [image_size, image_size, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 64, 64\n",
    "data_dir = '../face_data_test_ic'\n",
    "learning_rate= 0.0002\n",
    "beta1= 0.5\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "lambda_val = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    return image/127.5 - 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def minibatch_discrimination(input_tensor, name, num_kernels=100, kernel_dim=5):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        input_shape = input_tensor.get_shape().as_list()\n",
    "        print \"input-shape\" , input_shape\n",
    "        batch_size = input_shape[0]\n",
    "        print batch_size\n",
    "        features = input_shape[1]\n",
    "        print features\n",
    "        W = tf.get_variable(\"weight\", [features, num_kernels * kernel_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bias = tf.get_variable(\"bias\", [num_kernels], initializer=tf.constant_initializer(0.0))\n",
    "        activation = tf.matmul(input_tensor,W)\n",
    "        print activation.get_shape()\n",
    "        activation = tf.reshape(activation,[-1,num_kernels,kernel_dim])\n",
    "        a1 = tf.expand_dims(activation, 3)\n",
    "        a2 = tf.transpose(activation, perm=[1,2,0])\n",
    "        a2 = tf.expand_dims(a2, 0)\n",
    "        abs_diff = tf.reduce_sum(tf.abs(a1 - a2), reduction_indices=[2])\n",
    "        expsum  = tf.reduce_sum(tf.exp(-abs_diff), reduction_indices=[2])\n",
    "        expsum = expsum + bias\n",
    "        print expsum.get_shape()\n",
    "        return tf.concat([input_tensor,expsum],axis=1)\n",
    "\n",
    "def gaussian_noise_layer(input_tensor, std=0.2):\n",
    "    noise = tf.random_normal(shape=tf.shape(input_tensor), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "    return input_tensor + noise\n",
    "\n",
    "def lrelu(x,alpha=0.2):\n",
    "    return tf.maximum(x, alpha*x)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def linear(input_tensor, input_dim, output_dim, name=None):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable(\"weights\", [input_dim, output_dim], initializer=tf.truncated_normal_initializer(stddev=math.sqrt(3.0 / (input_dim + output_dim))))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input_tensor, weights) + bias \n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "def conv_2d(input_tensor, input_dim, output_dim, name=None):\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [5, 5,input_dim, output_dim], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.conv2d(input_tensor, kernel, strides=[1, 2, 2, 1],padding='SAME')\n",
    "        return conv+bias\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "def conv_2dtranspose(input_tensor, input_dim, output_shape,name=None):\n",
    "    output_dim=output_shape[-1]\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [5, 5, output_dim, input_dim], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.nn.conv2d_transpose(input_tensor, kernel, output_shape=output_shape, strides=[1, 2, 2, 1],padding='SAME')\n",
    "        return deconv+bias\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "def batch_norm(input_tensor,name,is_train=True):\n",
    "    return tf.contrib.layers.batch_norm(input_tensor,decay=0.9, updates_collections=None, epsilon=1e-5, scale=True,    \n",
    "                                        is_training=is_train, scope=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21709 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "load_img_datagen = ImageDataGenerator(preprocessing_function = preprocessing)\n",
    "img_input = load_img_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "#    z = tf.placeholder(tf.float32, [None, 100], name='z')\n",
    "    l1=linear(input_tensor=z,name=\"g_lin\", input_dim=100, output_dim=1024*4*4)  \n",
    "    l2= tf.reshape(l1, [-1, 4, 4, 1024])\n",
    "    l3 = lrelu(batch_norm(input_tensor=l2,name=\"g_bn0\"))\n",
    "    print l3\n",
    "    #conv1\n",
    "    l4=conv_2dtranspose(input_tensor=l3,name=\"g_c2dt1\",input_dim=1024,output_shape=[batch_size,8,8,512])\n",
    "    l5=lrelu(batch_norm(input_tensor=l4,name=\"g_bn1\"))\n",
    "    print l5\n",
    "    #conv2\n",
    "    l6=conv_2dtranspose(input_tensor=l5,name=\"g_c2dt2\",input_dim=512,output_shape=[batch_size,16,16,256])\n",
    "    l7=lrelu(batch_norm(input_tensor=l6,name='g_bn2'))\n",
    "    print l7\n",
    "    #conv3\n",
    "    l8=conv_2dtranspose(input_tensor=l7,name='g_c2dt3',input_dim=256,output_shape=[batch_size,32,32,128])\n",
    "    l9=lrelu(batch_norm(input_tensor=l8,name='g_bn3'))\n",
    "    print l9\n",
    "    #conv4\n",
    "    l10=conv_2dtranspose(input_tensor=l9,name='g_c2dt4',input_dim=128,output_shape=[batch_size,64,64,3])\n",
    "    l11=tf.nn.tanh(l10)\n",
    "    print l11\n",
    "    return l11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False, alpha=0.2):\n",
    "     with tf.variable_scope(\"discriminator\") as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        #naming of the layers is as per layer number    \n",
    "        #h0 conv2d no batch_norm\n",
    "        images = gaussian_noise_layer(images)\n",
    "        l1 = conv_2d(input_tensor=images, input_dim=3, output_dim= 64, name='d_c2d0')\n",
    "        l2 = lrelu(l1,alpha)\n",
    "\n",
    "        #h1 conv2d with batch_norm\n",
    "        l3 = conv_2d(input_tensor=l2, input_dim=64, output_dim=64*2, name='d_c2d1')\n",
    "        l4 = batch_norm(input_tensor=l3,name=\"d_bn1\")\n",
    "        l5 = lrelu(l4,alpha)\n",
    "\n",
    "        #h2 conv2d with batch_norm\n",
    "        l6 = conv_2d(input_tensor=l5, input_dim=64*2, output_dim=64*4, name='d_c2d2')\n",
    "        l7 = batch_norm(input_tensor=l6,name=\"d_bn2\")\n",
    "        l8 = lrelu(l7,alpha)\n",
    "\n",
    "        #h3 conv2d with batch_norm\n",
    "        l9 = conv_2d(input_tensor=l8, input_dim=64*4, output_dim=64*8, name='d_c2d3')\n",
    "        l10 = batch_norm(input_tensor=l9,name=\"d_bn3\")\n",
    "        l11 = lrelu(l10,alpha)\n",
    "\n",
    "        #h4 reshape and linear\n",
    "        l12 = tf.reshape(l11, [-1, 8192]) #l12 = tf.reshape(l11, [32, -1]) #l12 = tf.reshape(l11, [64, -1])\n",
    "        l13 = minibatch_discrimination(l12,name=\"d_mini\",num_kernels=100)\n",
    "        print l13.get_shape()\n",
    "        input_dim_linear = l13.get_shape().as_list()\n",
    "        l14 = linear(input_tensor=l13, input_dim=input_dim_linear[1], output_dim=1, name=\"d_lin4\")\n",
    "        print l14.get_shape().as_list()\n",
    "        #sigmoid\n",
    "        #minibatch discrimination layer\n",
    "\n",
    "        l15 = tf.nn.sigmoid(l14)\n",
    "        print l15\n",
    "        return l15, l14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Maximum:0\", shape=(?, 4, 4, 1024), dtype=float32)\n",
      "Tensor(\"Maximum_1:0\", shape=(64, 8, 8, 512), dtype=float32)\n",
      "Tensor(\"Maximum_2:0\", shape=(64, 16, 16, 256), dtype=float32)\n",
      "Tensor(\"Maximum_3:0\", shape=(64, 32, 32, 128), dtype=float32)\n",
      "Tensor(\"Tanh:0\", shape=(64, 64, 64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "z = tf.placeholder(tf.float32, [None, 100], name='z')\n",
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(\n",
    "            tf.float32, [None] + image_shape, name='real_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input-shape [None, 8192]\n",
      "None\n",
      "8192\n",
      "(?, 500)\n",
      "(?, 100)\n",
      "(?, 8292)\n",
      "[None, 1]\n",
      "Tensor(\"discriminator/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "D1, D1_logits = discriminator(images, False, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input-shape [64, 8192]\n",
      "64\n",
      "8192\n",
      "(64, 500)\n",
      "(64, 100)\n",
      "(64, 8292)\n",
      "[64, 1]\n",
      "Tensor(\"discriminator_1/Sigmoid:0\", shape=(64, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "D2, D2_logits = discriminator(G, True, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t_vars=tf.trainable_variables()\n",
    "discrim_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "gen_vars = [var for var in t_vars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "discrim_loss_real_img = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D1_logits, labels=tf.scalar_mul(0.9,tf.ones_like(D1_logits))))\n",
    "discrim_loss_fake_img = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_logits, labels=tf.zeros_like(D2_logits)))\n",
    "discrim_loss = discrim_loss_real_img + discrim_loss_fake_img\n",
    "gen_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_logits, labels=tf.ones_like(D2_logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7f91a7c900d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7c90110>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7ca1c10>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7ca1c90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7cb2b90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7c47550>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7c276d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7c27750>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7c388d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7c38fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7bac190>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7bac210>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7bbc390>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7bbca90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7b21dd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7b21ed0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7ade990>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7f91a7adeb90>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrim_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dopt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(discrim_loss, var_list=discrim_vars)\n",
    "gopt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load(checkpoint_dir):\n",
    "    print(\" [*] Reading checkpoints...\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "isLoaded = load('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isLoaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mask = tf.placeholder(tf.float32, [None] + image_shape, name='mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imp_matrix = tf.placeholder(tf.float32, [None] + image_shape, name='imp_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-b780f5b0258b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-b780f5b0258b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    tf.abs(tf.multiply(tf.cast(mask,tf.float32), tf.cast(G,tf.float32)) - tf.multiply(tf.cast(mask,tf.float32), tf.cast(images, tf.float32))))), 1)\u001b[0m\n\u001b[0m                                                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "contextual_loss = tf.reduce_sum(\n",
    "    tf.contrib.layers.flatten(\n",
    "        tf.abs(tf.multiply(tf.cast(mask,tf.float32), tf.cast(G,tf.float32)) - tf.multiply(tf.cast(mask,tf.float32), tf.cast(images, tf.float32))))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "perceptual_loss = gen_loss\n",
    "complete_loss = contextual_loss + lambda_val*perceptual_loss\n",
    "grad_complete_loss = tf.gradients(complete_loss, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get input image y\n",
    "real_images=next(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_images = np.array(real_images).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img = (real_images[1,:,:,:] +1.)/2\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config['maskType'] = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config['learning_rate'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config['momentum'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get mask M\n",
    "if config['maskType'] == 'random':\n",
    "    fraction_masked = 0.2\n",
    "    mask_ = np.ones(image_shape)\n",
    "    mask_[np.random.random(image_shape[:2]) < fraction_masked] = 0.0\n",
    "elif config['maskType'] == 'center':\n",
    "    scale = 0.25\n",
    "    #assert(scale <= 0.5)\n",
    "    mask_ = np.ones(image_shape)\n",
    "    sz = image_size\n",
    "    l = int(image_size*scale)\n",
    "    u = int(image_size*(1.0-scale))\n",
    "    mask_[l:u, l:u, :] = 0.0\n",
    "elif config['maskType'] == 'left':\n",
    "    mask_ = np.ones(image_shape)\n",
    "    c = image_size // 2\n",
    "    mask_[:,:c,:] = 0.0\n",
    "elif config['maskType'] == 'full':\n",
    "    mask_ = np.ones(image_shape)\n",
    "else:\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_images(image_batch, size):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    c = image_batch.shape[3]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1], c))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w,:] = im\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the importance matrix\n",
    "\n",
    "a=np.ones((64,64))\n",
    "n=64\n",
    "for k in range(1,16):\n",
    "    for i in range(k,n-k):\n",
    "        for j in range(k,n-k):\n",
    "            a[i,j]+=1\n",
    "\n",
    "scale=0.25\n",
    "image_size=64\n",
    "sz = image_size\n",
    "l = int(image_size*scale)\n",
    "u = int(image_size*(1.0-scale))\n",
    "a[l:u, l:u] = 0.0\n",
    "\n",
    "non_zero_mean = np.sum(a)/(32*32)\n",
    "\n",
    "importance_matrix = a/32#non_zero_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#batch_images = ...\n",
    "batch_mask = np.resize(mask_, [batch_size] + image_shape)\n",
    "#imp_mask = np.resize(importance_matrix, [batch_size] + image_shape)\n",
    "zhats = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "\n",
    "vel = 0\n",
    "for i in xrange(5000):\n",
    "    fd = {\n",
    "        z: zhats,\n",
    "        #imp_matrix: imp_mask,\n",
    "        mask: batch_mask,\n",
    "        images: batch_images,\n",
    "    }\n",
    "    run = [complete_loss, grad_complete_loss, G]\n",
    "    loss, g, G_imgs = sess.run(run, feed_dict=fd)\n",
    "    \n",
    "    if (i%500 is 0):\n",
    "        print \"loss in iteration: \" + str(i) + \" is: \" + str(np.mean(loss))\n",
    "\n",
    "    prev_vel = np.copy(vel)\n",
    "    vel = config['momentum']*vel - config['learning_rate']*g[0]\n",
    "    zhats += -config['momentum'] * prev_vel + (1+config['momentum'])*vel\n",
    "    zhats = np.clip(zhats, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "created_images = (G_imgs + 1.)/2\n",
    "im = merge_images(created_images, [8,8])\n",
    "plt.imshow(im)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "masked_images = np.multiply(batch_images, batch_mask)\n",
    "input_images = (masked_images + 1.)/2\n",
    "im = merge_images(input_images, [8,8])\n",
    "plt.imshow(im)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_mask_ = 1- mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv_batch_mask = np.resize(inv_mask_, [batch_size] + image_shape)\n",
    "inv_masked_images = np.multiply(batch_images, inv_batch_mask)\n",
    "\n",
    "inv_input_images = (inv_masked_images + 1.)/2\n",
    "im_ = merge_images(inv_input_images, [8,8])\n",
    "plt.imshow(im_)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv_batch_mask = np.resize(inv_mask_, [batch_size] + image_shape)\n",
    "inv_masked_images = np.multiply(G_imgs, inv_batch_mask)\n",
    "\n",
    "Recons_img = inv_masked_images + masked_images\n",
    "\n",
    "rec_images = (Recons_img + 1.)/2\n",
    "im_r = merge_images(rec_images, [8,8])\n",
    "plt.imshow(im_r)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
