{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6> Objective</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6> Theory</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =2>Training Procedure</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/training_proced.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =2>Architecture</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/generator_architecture.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/discrim_arch.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6> Dataset</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Flowers: 102 Category Flower Dataset, Visual Geometry Group, University of Oxford</b>\n",
    "\n",
    "http://www.robots.ox.ac.uk/~vgg/data/flowers/102/\n",
    "\n",
    "~8,000 images from 102 categories\n",
    "\n",
    "After augmentation: https://www.dropbox.com/s/2n7qd2qq39hsmnw/jpg2.zip?dl=0\n",
    "\n",
    "\n",
    "Some Samples\n",
    "<img src='images/flower_training_set.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Faces:</b>\n",
    "\n",
    "<b>Large-scale CelebFaces Attributes (CelebA) Dataset, Multimedia Laboratory, The Chinese University of Hong Kong</b>\n",
    "\n",
    "202,599 images of celebrity faces\n",
    "\n",
    "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "\n",
    "\n",
    "<b>LFWcrop Face Dataset</b>: \n",
    "\n",
    "13,233 images of human faces\n",
    "\n",
    "http://conradsanderson.id.au/lfwcrop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some samples:\n",
    "<img src='images/faces_training_set.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curated: Cropped:64x64x3, Flowers augumented, Train-Test Split......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6> Checking for Robustness: Nearest Neighbor</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/face_nn.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/flower_nn.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6> Generation: Results</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =4> Training</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Early Results</b>\n",
    "<img src='images/flower_early_results.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Flowers</b>\n",
    "<img src='images/flower_generation_training.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Faces</b>\n",
    "<img src='images/face_generation_training.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =4> Some Final Results</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Flowers</b>\n",
    "<img src='images/flower_gen.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Faces</b>\n",
    "<img src='images/face_gen.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6> Face Completion Results</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Flowers</b>\n",
    "<img src='images/image_reconstruction.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Flowers</b>\n",
    "<img src='images/flower_completion.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Faces</b>\n",
    "<img src='images/face_completion.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Completing our faces</b>\n",
    "<img src='images/face_completion_us.jpg'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size =6>References</font></b>\n",
    "<ul>References\n",
    "<li> Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in neural information processing systems. 2014.</li>\n",
    "<li> Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 2015.</li>\n",
    "<li>Salimans, Tim, et al. \"Improved techniques for training gans.\" Advances in Neural Information Processing Systems. 2016.</li>\n",
    "<li>Yeh, Raymond, et al. \"Semantic Image Inpainting with Perceptual and Contextual Losses.\" arXiv preprint arXiv:1607.07539 2016. </li>\n",
    "<li> Chen, Xi, et al. \"Infogan: Interpretable representation learning by information maximizing generative adversarial nets.\" Advances in Neural Information Processing Systems. 2016.</li>\n",
    "<li>Denton, Emily L., Soumith Chintala, and Rob Fergus. \"Deep Generative Image Models using a￼ Laplacian Pyramid of Adversarial Networks.\" Advances in neural information processing systems. 2015. </li>\n",
    "<li> Ledig, Christian, et al. \"Photo-realistic single image super-resolution using a generative adversarial network.\" arXiv preprint arXiv:1609.04802 (2016).</li>\n",
    "<li> Reed, Scott E., et al. \"Learning what and where to draw.\" Advances In Neural Information Processing Systems. 2016. </li>\n",
    "<li> Isola, Phillip, et al. \"Image-to-image translation with conditional adversarial networks.\" arXiv preprint arXiv:1611.07004 2016. </li>\n",
    "<li> Zhang, Han, et al. \"StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.\" arXiv preprint arXiv:1612.03242 (2016). </li>\n",
    "<li> Wang, Xiaolong, and Abhinav Gupta. \"Generative image modeling using style and structure adversarial networks.\" European Conference on Computer Vision. Springer International Publishing, 2016.</li>\n",
    "<li>Xie, Junyuan, Linli Xu, and Enhong Chen. \"Image denoising and inpainting with deep neural networks.\" Advances in Neural Information Processing Systems. 2012.</li>\n",
    "<li>Köhler, Rolf, et al. \"Mask-specific inpainting with deep neural networks.\" German Conference on Pattern Recognition. Springer International Publishing, 2014.</li>\n",
    "<li>Dosovitskiy, Alexey, and Thomas Brox. \"Generating images with perceptual similarity metrics based on deep networks.\" Advances in Neural Information Processing Systems. 2016.</li>\n",
    "<li> Sauer, Christopher, Russell Kaplan, and Alexander Lin. \"Neural Fill: Content Aware Image Fill with Generative Adversarial Neural Networks.\" </li>\n",
    "<li>https://en.wikipedia.org/wiki/Generative_adversarial_networks</li>\n",
    "<li> https://github.com/jacobgil/keras-dcgan </li>\n",
    "<li> http://bamos.github.io/2016/08/09/deep-completion/ </li>\n",
    "<li> https://github.com/soumith/dcgan.torch </li>\n",
    "<li> https://github.com/carpedm20/DCGAN-tensorflow </li>\n",
    "<li> https://github.com/rajathkumarmp/DCGAN </li>\n",
    "\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
