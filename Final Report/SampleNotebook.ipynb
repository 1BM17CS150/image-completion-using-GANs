{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents -\n",
    "<ul>\n",
    "<li>Data Cleaning - augmentation</li>\n",
    "<li>Final configuration - Keras, Tensorflow</li>\n",
    "<li>Nearest Neighbor</li>\n",
    "<li>Image Completion</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Data Cleaning - augmentation, cropping, conversions</b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import glob, os, sys\n",
    "import scipy.misc\n",
    "\n",
    "for filename in glob.glob('/home/icarus/Documents/DCGAN_Tensorflow/FacesDataset/data/celebA/*'):\n",
    "     image = scipy.misc.imread(filename)\n",
    "     f, e = os.path.splitext(filename)\n",
    "     outname = f + \"_cropped\" + e\n",
    "     im2 = scipy.misc.imresize(image[55:163, 30:148], [64,64])\n",
    "     scipy.misc.imsave(outname, im2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import glob, os, sys\n",
    "\n",
    "count = 0\n",
    "\n",
    "for filename in glob.glob('/home/icarus/Documents/DCGAN_Tensorflow/FacesDataset/faces/*'):\n",
    "    f, e = os.path.splitext(filename)\n",
    "    outfile = f + \".jpg\"\n",
    "    count += 1\n",
    "    print outfile\n",
    "    try:\n",
    "        Image.open(filename).save(outfile)\n",
    "    except IOError:\n",
    "        print \"cannot convert\" + filename\n",
    "\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Shrinks and augments downloaded images in order to create a training set.\"\"\"\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from ImageAugmenter import ImageAugmenter\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "KEYWORDS = [\"flowers\"]\n",
    "\n",
    "MAIN_DIR = os.path.dirname(os.path.realpath(__file__))\n",
    "READ_MAIN_DIR = os.path.join(MAIN_DIR, \"downloaded2/\")\n",
    "WRITE_MAIN_DIR = os.path.join(MAIN_DIR, \"pre_fl/\")\n",
    "DIRS = [(os.path.join(READ_MAIN_DIR, \"%s/\" % (keyword,)), \\\n",
    "         os.path.join(WRITE_MAIN_DIR, \"%s/\" % (keyword,))) for keyword in KEYWORDS]\n",
    "\n",
    "SCALE_HEIGHT = 64\n",
    "SCALE_WIDTH = 64\n",
    "RATIO_WIDTH_TO_HEIGHT = 1\n",
    "EPSILON = 0.1\n",
    "\n",
    "AUGMENTATIONS = 10\n",
    "PADDING = 20\n",
    "\n",
    "def main():\n",
    "    \"\"\"Iterates over the images in each directory, shrinks and augments each one.\"\"\"\n",
    "    nb_processed = 0\n",
    "    nb_errors = 0\n",
    "    nb_total = len(get_all_filepaths([download_dir for download_dir, write_to_dir in DIRS]))\n",
    "\n",
    "    # iterate over directories (read-directory and save-to-directory)\n",
    "    for download_dir, write_to_dir in DIRS:\n",
    "        print(\"Reading from '%s'\" % (download_dir,))\n",
    "        print(\"Writing to '%s'\" % (write_to_dir,))\n",
    "\n",
    "        # create directory if it doesnt exist\n",
    "        if not os.path.exists(write_to_dir):\n",
    "            os.makedirs(write_to_dir)\n",
    "\n",
    "        # load filepaths of images in directory\n",
    "        fps_img = get_all_filepaths([download_dir])\n",
    "\n",
    "        # iterate over each image\n",
    "        for fp_img in fps_img:\n",
    "            print(\"Image %d of %d (%.2f%%) (%s)\" \\\n",
    "                  % (nb_processed+1, nb_total, 100*(nb_processed+1)/nb_total, fp_img))\n",
    "            try:\n",
    "                filename = fp_img[fp_img.rfind(\"/\")+1:]\n",
    "                # dont use misc.imload, fails for grayscale images\n",
    "                image = ndimage.imread(fp_img, mode=\"RGB\")\n",
    "                image_orig = np.copy(image)\n",
    "                misc.imshow(image)\n",
    "                print(image)\n",
    "                print(image.shape)\n",
    "\n",
    "                height = image_orig.shape[0]\n",
    "                width = image_orig.shape[1]\n",
    "                wh_ratio = width / height\n",
    "\n",
    "                \n",
    "                # add padding at the borders of the image\n",
    "                # then augment image\n",
    "                batch = np.zeros((AUGMENTATIONS, height+(2*PADDING), width+(2*PADDING), 3),\n",
    "                                 dtype=np.uint8)\n",
    "\n",
    "                img_padded = np.pad(image, ((PADDING, PADDING), (PADDING, PADDING), (0, 0)),\n",
    "                                    mode=\"median\")\n",
    "                for i in range(0, AUGMENTATIONS):\n",
    "                    batch[i] = np.copy(img_padded)\n",
    "                    ia = ImageAugmenter(width+(2*PADDING), height+(2*PADDING),\n",
    "                                    channel_is_first_axis=False,\n",
    "                                    hflip=True, vflip=False,\n",
    "                                    scale_to_percent=(1.05, 1.2), scale_axis_equally=True,\n",
    "                                    rotation_deg=5, shear_deg=1,\n",
    "                                    translation_x_px=15, translation_y_px=15)\n",
    "                    batch = ia.augment_batch(batch)\n",
    "\n",
    "\n",
    "                    for i in range(0, AUGMENTATIONS):\n",
    "                        image_resized = misc.imresize(image, (SCALE_HEIGHT, SCALE_WIDTH))\n",
    "                    # save augmented image\n",
    "                        filename_aug = filename.replace(\".jp\", \"__%d.jp\" % (i))\n",
    "                        misc.imsave(os.path.join(write_to_dir, filename_aug), image_resized)\n",
    "            except IOError as exc:\n",
    "                # sometimes downloaded images cannot be read by imread()\n",
    "                # this should catch these cases\n",
    "                    print(\"I/O error({0}): {1}\".format(exc.errno, exc.strerror))\n",
    "                    nb_errors += 1\n",
    "\n",
    "            nb_processed += 1\n",
    "\n",
    "        print(\"Processed %d images\" % (nb_processed,))\n",
    "        print(\"Encountered %d errors\" % (nb_errors,))\n",
    "        print(\"Finished.\")\n",
    "\n",
    "def get_all_filepaths(fp_dirs):\n",
    "    \"\"\"Reads all filepaths to images in provided directories.\n",
    "    Args:\n",
    "        fp_dirs The list of directories\n",
    "    Returns:\n",
    "        List of filepaths to images\n",
    "    \"\"\"\n",
    "    result_img = []\n",
    "    for fp_dir in fp_dirs:\n",
    "        fps = [f for f in os.listdir(fp_dir) if os.path.isfile(os.path.join(fp_dir, f))]\n",
    "        fps = [os.path.join(fp_dir, f) for f in fps]\n",
    "        fps_img = [fp for fp in fps if re.match(r\".*\\.(?:jpg|jpeg|png)$\", fp)]\n",
    "        result_img.extend(fps_img)\n",
    "\n",
    "    return result_img\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tensorflow</b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time as ti\n",
    "import csv\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from pympler import asizeof\n",
    "import time as ti\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "def lrelu(x,alpha=0.2):\n",
    "    return tf.maximum(x, alpha*x)\n",
    "\n",
    "def gaussian_noise_layer(input_tensor, std=0.2):\n",
    "    noise = tf.random_normal(shape=tf.shape(input_tensor), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "    return input_tensor + noise\n",
    "\n",
    "def linear(input_tensor, input_dim, output_dim, name=None):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable(\"weights\", [input_dim, output_dim], initializer=tf.truncated_normal_initializer(stddev=math.sqrt(3.0 / (input_dim + output_dim))))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input_tensor, weights) + bias \n",
    "\n",
    "def conv_2d(input_tensor, input_dim, output_dim, name=None):\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [5, 5,input_dim, output_dim], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.conv2d(input_tensor, kernel, strides=[1, 2, 2, 1],padding='SAME')\n",
    "        return conv+bias\n",
    "\n",
    "def conv_2dtranspose(input_tensor, input_dim, output_shape,name=None):\n",
    "    output_dim=output_shape[-1]\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [5, 5, output_dim, input_dim], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.nn.conv2d_transpose(input_tensor, kernel, output_shape=output_shape, strides=[1, 2, 2, 1],padding='SAME')\n",
    "        return deconv+bias\n",
    "\n",
    "def batch_norm(input_tensor,name,is_train=True):\n",
    "    return tf.contrib.layers.batch_norm(input_tensor,decay=0.9, updates_collections=None, epsilon=1e-5, scale=True,    \n",
    "                                        is_training=is_train, scope=name)\n",
    "\n",
    "def show_sample(X):\n",
    "    im = X\n",
    "    plt.imshow(im)\n",
    "    plt.axis('on')\n",
    "    plt.show()  \n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "def generator(z):\n",
    "    l1=linear(input_tensor=z,name=\"g_lin\", input_dim=100, output_dim=1024*4*4)  \n",
    "    l2= tf.reshape(l1, [-1, 4, 4, 1024])\n",
    "    l3 = lrelu(batch_norm(input_tensor=l2,name=\"g_bn0\"))\n",
    "    print l3\n",
    "    #conv1\n",
    "    l4=conv_2dtranspose(input_tensor=l3,name=\"g_c2dt1\",input_dim=1024,output_shape=[batch_size,8,8,512])\n",
    "    l5=lrelu(batch_norm(input_tensor=l4,name=\"g_bn1\"))\n",
    "    print l5\n",
    "    #conv2\n",
    "    l6=conv_2dtranspose(input_tensor=l5,name=\"g_c2dt2\",input_dim=512,output_shape=[batch_size,16,16,256])\n",
    "    l7=lrelu(batch_norm(input_tensor=l6,name='g_bn2'))\n",
    "    print l7\n",
    "    #conv3\n",
    "    l8=conv_2dtranspose(input_tensor=l7,name='g_c2dt3',input_dim=256,output_shape=[batch_size,32,32,128])\n",
    "    l9=lrelu(batch_norm(input_tensor=l8,name='g_bn3'))\n",
    "    print l9\n",
    "    #conv4\n",
    "    l10=conv_2dtranspose(input_tensor=l9,name='g_c2dt4',input_dim=128,output_shape=[batch_size,64,64,3])\n",
    "    l11=tf.nn.tanh(l10)\n",
    "    print l11\n",
    "    return l11\n",
    "\n",
    "def minibatch_discrimination(input_tensor, name, num_kernels=100, kernel_dim=5):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        input_shape = input_tensor.get_shape().as_list()\n",
    "        print \"input-shape\" , input_shape\n",
    "        features = input_shape[1]\n",
    "        print features\n",
    "        W = tf.get_variable(\"weight\", [features, num_kernels * kernel_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bias = tf.get_variable(\"bias\", [num_kernels], initializer=tf.constant_initializer(0.0))\n",
    "        activation = tf.matmul(input_tensor,W)\n",
    "        print activation.get_shape()\n",
    "        activation = tf.reshape(activation,[-1,num_kernels,kernel_dim])\n",
    "        a1 = tf.expand_dims(activation, 3)\n",
    "        a2 = tf.transpose(activation, perm=[1,2,0])\n",
    "        a2 = tf.expand_dims(a2, 0)\n",
    "        abs_diff = tf.reduce_sum(tf.abs(a1 - a2), reduction_indices=[2])\n",
    "        expsum  = tf.reduce_sum(tf.exp(-abs_diff), reduction_indices=[2])\n",
    "        expsum = expsum + bias\n",
    "        print expsum.get_shape()\n",
    "        return tf.concat([input_tensor,expsum],axis=1)\n",
    "\n",
    "def discriminator(images, reuse=False, alpha=0.2):\n",
    "     with tf.variable_scope(\"discriminator\") as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        images = gaussian_noise_layer(images)\n",
    "        #naming of the layers is as per layer number    \n",
    "        #h0 conv2d no batch_norm\n",
    "        l1 = conv_2d(input_tensor=images, input_dim=3, output_dim= 64, name='d_c2d0')\n",
    "        l2 = lrelu(l1,alpha)\n",
    "\n",
    "        #h1 conv2d with batch_norm\n",
    "        l3 = conv_2d(input_tensor=l2, input_dim=64, output_dim=64*2, name='d_c2d1')\n",
    "        l4 = batch_norm(input_tensor=l3,name=\"d_bn1\")\n",
    "        l5 = lrelu(l4,alpha)\n",
    "\n",
    "        #h2 conv2d with batch_norm\n",
    "        l6 = conv_2d(input_tensor=l5, input_dim=64*2, output_dim=64*4, name='d_c2d2')\n",
    "        l7 = batch_norm(input_tensor=l6,name=\"d_bn2\")\n",
    "        l8 = lrelu(l7,alpha)\n",
    "\n",
    "        #h3 conv2d with batch_norm\n",
    "        l9 = conv_2d(input_tensor=l8, input_dim=64*4, output_dim=64*8, name='d_c2d3')\n",
    "        l10 = batch_norm(input_tensor=l9,name=\"d_bn3\")\n",
    "        l11 = lrelu(l10,alpha)\n",
    "\n",
    "        #h4 reshape and linear\n",
    "        #minibatch discrimination layer\n",
    "        l12 = tf.reshape(l11, [-1, 8192]) #l12 = tf.reshape(l11, [32, -1]) #l12 = tf.reshape(l11, [64, -1])\n",
    "        l13 = minibatch_discrimination(l12,name=\"d_mini\",num_kernels=100)\n",
    "        print l13.get_shape()\n",
    "        input_dim_linear = l13.get_shape().as_list()\n",
    "        l14 = linear(input_tensor=l13, input_dim=input_dim_linear[1], output_dim=1, name=\"d_lin4\")\n",
    "        print l14.get_shape().as_list()\n",
    "        #sigmoid\n",
    "\n",
    "        l15 = tf.nn.sigmoid(l14)\n",
    "        print l15\n",
    "        return l15, l14\n",
    "\n",
    "#place holders for images and z\n",
    "#z = tf.placeholder(tf.float32,name='z')\n",
    "z = tf.placeholder(tf.float32, [None, 100], name='z')\n",
    "G=generator(z)\n",
    "#placeholder for images\n",
    "images = tf.placeholder(tf.float32, [None,64,64,3], name='images')\n",
    "alpha = 0.2\n",
    "D1, D1_logits = discriminator(images, False, alpha)\n",
    "D2, D2_logits = discriminator(G, True, alpha)\n",
    "\n",
    "#cretae list of discrim and gen vars\n",
    "t_vars=tf.trainable_variables()\n",
    "for var in t_vars:\n",
    "    print var.name\n",
    "discrim_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "gen_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "img_width, img_height = 64, 64\n",
    "data_dir = './final_face_data'\n",
    "learning_rate= 0.0002\n",
    "beta1= 0.5\n",
    "batch_size=64\n",
    "\n",
    "#LOSS\n",
    "discrim_loss_real_img = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D1_logits, labels=tf.scalar_mul(0.9,tf.ones_like(D1_logits))))\n",
    "discrim_loss_fake_img = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_logits, labels=tf.zeros_like(D2_logits)))\n",
    "discrim_loss = discrim_loss_real_img + discrim_loss_fake_img\n",
    "gen_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_logits, labels=tf.ones_like(D2_logits)))\n",
    "\n",
    "#optimizers\n",
    "dopt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(discrim_loss, var_list=discrim_vars)\n",
    "gopt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)\n",
    "\n",
    "def preprocessing(image):\n",
    "    return image/127.5 - 1;\n",
    "\n",
    "load_img_datagen = ImageDataGenerator(preprocessing_function = preprocessing)\n",
    "img_input = load_img_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "\n",
    "sess = tf.Session()\n",
    "#sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "d_loss_all=[]\n",
    "g_loss_all=[]\n",
    "\n",
    "def merge_images(image_batch, size):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    c = image_batch.shape[3]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1], c))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w,:] = im\n",
    "    return img\n",
    "\n",
    "def save_image(X, iter, fl):\n",
    "    #im = Image.fromarray(X)\n",
    "    name = 'Iteration' + str(iter) + 'time' + str(ti.time()) + '.png'\n",
    "    #im.save(name)\n",
    "    if (fl == False):\n",
    "        name = 'Random'+name\n",
    "    size = [8,8]\n",
    "    #change X back\n",
    "    X[0] = (X[0] + 1.)/2\n",
    "\n",
    "    im = merge_images(X[0], size)\n",
    "    scipy.misc.imsave(name, im)\n",
    "\n",
    "def save_sample(X, iter, fl):\n",
    "    im = X\n",
    "    plt.imshow(im)\n",
    "    plt.axis('on')\n",
    "    #plt.show()\n",
    "    name = 'Iteration' + str(iter) + 'time' + str(ti.time()) + '.png'\n",
    "    plt.savefig(name)\n",
    "\n",
    "disp_img_noise = np.random.uniform(-1,1,size=[batch_size,100])\n",
    "saver = tf.train.Saver()\n",
    "f = open('train.log', 'w+')\n",
    "iters = 50000\n",
    "\n",
    "for i in range(iters):\n",
    "    #train discriminator\n",
    "    real_images=next(img_input)\n",
    "    noise= np.random.uniform(-1,1,size=[batch_size,100])\n",
    "    sess.run([dopt],feed_dict={z:noise,images:real_images})\n",
    "\n",
    "    #train discriminator\n",
    "    real_images=next(img_input)\n",
    "    noise= np.random.uniform(-1,1,size=[batch_size,100])\n",
    "    sess.run([dopt],feed_dict={z:noise,images:real_images})    \n",
    "    \n",
    "    #gen\n",
    "    noise= np.random.uniform(-1,1,size=[batch_size,100])\n",
    "    sess.run([gopt],feed_dict={z:noise})\n",
    "\n",
    "    if (np.sum(g_loss_all[-100:]) > 150):\n",
    "        noise= np.random.uniform(-1,1,size=[batch_size,100])\n",
    "        sess.run([gopt],feed_dict={z:noise})\n",
    "        f.write('Extra Generator in iteration: ' + str(i) + ' sum of last 100: ' + str(np.sum(g_loss_all[-100:])) + '\\n')\n",
    "        print 'Extra Generator in iteration: ' + str(i) + ' sum of last 100: ' + str(np.sum(g_loss_all[-100:]))\n",
    "\n",
    "    #evaluate \n",
    "    noise_tr= np.random.uniform(-1,1,size=[batch_size,100])\n",
    "    real_images=next(img_input)\n",
    "    #train generator\n",
    "    \n",
    "    d_loss_all.append(sess.run([discrim_loss],feed_dict={z:noise_tr, images:real_images}))\n",
    "    g_loss_all.append(sess.run([gen_loss], feed_dict={z:noise_tr}))\n",
    "\n",
    "    print 'iteration: ' + str(i) + ' g_loss:' + str(g_loss_all[-1]) + ' d_loss:' + str(d_loss_all[-1])\n",
    "    #print i, g_loss_all[-1], d_loss_all[-1]\n",
    "    \n",
    "    if (i%1000 == 0):\n",
    "        losses_list = [g_loss_all, d_loss_all]\n",
    "        with open('loss.csv', 'w') as loss_file:\n",
    "            writer = csv.writer(loss_file)\n",
    "            writer.writerows(losses_list)\n",
    "        fake_img = sess.run([G],feed_dict={z:disp_img_noise})#[0][0]\n",
    "        #show_sample(fake_img)\n",
    "        save_image(fake_img, i, True)\n",
    "        #save_sample(fake_img, i, True)\n",
    "        random_noise = np.random.uniform(-1,1,size=[batch_size,100])\n",
    "        save_image(sess.run([G],feed_dict={z:random_noise}), i, False)\n",
    "        name = 'saved_model.ckpt'\n",
    "        saver.save(sess,name)\n",
    "    \n",
    "    log_string =  'iteration: ' + str(i) + ' g_loss:' + str(g_loss_all[-1]) + ' d_loss:' + str(d_loss_all[-1])\n",
    "    f.write(log_string)\n",
    "    f.write('\\n')\n",
    "    f.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Nearest Neighbor </b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "image_list = []\n",
    "f=open('img_processed.log','w+')\n",
    "\n",
    "for filename in glob.glob('/home/nishant.puri2577/data/jpg2/*'):\n",
    "    im=misc.imread(filename)\n",
    "    image_list.append(im)\n",
    "\n",
    "print len(image_list)\n",
    "\n",
    "train=image_list[0].reshape(12288)\n",
    "\n",
    "for i in range(1,len(image_list)):\n",
    "    if(i%100==0):\n",
    "        f.write('images processed' + str(i))\n",
    "        f.write('\\n')\n",
    "        f.flush()\n",
    "    train=np.vstack((train,image_list[i].reshape(12288)))\n",
    "\n",
    "np.savetxt(\"train.csv\", train, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "#import utils\n",
    "matplotlib.use('Agg')\n",
    "from pylab import figure, axes, pie, title, show\n",
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "from scipy import misc\n",
    "#import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "train=pd.read_csv(\"/home/nishant.puri2577/data/train_nparray/train.csv\")\n",
    "\n",
    "train=train.values\n",
    "print train.shape\n",
    "train=train.astype(np.uint8)\n",
    "\n",
    "train=train/256.\n",
    "image_list = []\n",
    "for filename in glob.glob('/home/nishant.puri2577/data/generated_faces/*'):\n",
    "    im=misc.imread(filename)\n",
    "    image_list.append(im)\n",
    "test=image_list[0].reshape(12288)\n",
    "for i in range(1,len(image_list)):\n",
    "    test=np.vstack((test,image_list[i].reshape(12288)))\n",
    "\n",
    "test=test/256.\n",
    "\n",
    "cnt_test=test.shape[0]\n",
    "cnt_train=train.shape[0]\n",
    "\n",
    "train_sq_sum=np.sum(train*train,axis=1)\n",
    "train_sq=np.repeat(train_sq_sum.reshape((1,train_sq_sum.shape[0])),cnt_test,axis=0)\n",
    "\n",
    "test_sq_sum=np.sum(test*test,axis=1)\n",
    "test_sq=np.repeat(test_sq_sum.reshape((test_sq_sum.shape[0],1)),cnt_train,axis=1)\n",
    "\n",
    "c=train_sq+test_sq-2*test.dot(train.T)\n",
    "\n",
    "closest_image_idx=np.argmin(c,1)\n",
    "min_dist=np.min(c,1)\n",
    "\n",
    "def closest_im(i):\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    image=(test[i]*256).astype(np.uint8)\n",
    "    #show_sample(image)\n",
    "    image_nn=train[closest_image_idx[i],:]\n",
    "    l2_dist=np.sqrt(min_dist[i])\n",
    "    #print \"l2 distance is: \", l2_dist\n",
    "    image_nn=(image_nn*256).astype(np.uint8)\n",
    "    #show_sample(image_nn)\n",
    "    image=image.reshape((64,64,3))\n",
    "    image_nn=image_nn.reshape((64,64,3))\n",
    "    plt.figure()\n",
    "    plt.suptitle('L2 distance: '+str(l2_dist),fontsize=16)\n",
    "    plt.figure(1)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Generated Image')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(image_nn)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('Closest Neighbor')\n",
    "    #plt.suptitle('L2 distance: '+str(l2_dist),fontsize=16)\n",
    "    plt.savefig('gen_closest'+ str(i) + '_' + str(l2_dist) + '.png')\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    closest_im(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Image Completion </b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time as ti\n",
    "import csv\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from pympler import asizeof\n",
    "import time as ti\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "image_size = 64\n",
    "image_shape = [image_size, image_size, 3]\n",
    "\n",
    "img_width, img_height = 64, 64\n",
    "data_dir = '../face_data_test_ic'\n",
    "learning_rate= 0.0002\n",
    "beta1= 0.5\n",
    "batch_size=64\n",
    "\n",
    "alpha = 0.2\n",
    "lambda_val = 0.001\n",
    "\n",
    "def preprocessing(image):\n",
    "    return image/127.5 - 1;\n",
    "\n",
    "\n",
    "def minibatch_discrimination(input_tensor, name, num_kernels=100, kernel_dim=5):\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        input_shape = input_tensor.get_shape().as_list()\n",
    "        print \"input-shape\" , input_shape\n",
    "        batch_size = input_shape[0]\n",
    "        print batch_size\n",
    "        features = input_shape[1]\n",
    "        print features\n",
    "        W = tf.get_variable(\"weight\", [features, num_kernels * kernel_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bias = tf.get_variable(\"bias\", [num_kernels], initializer=tf.constant_initializer(0.0))\n",
    "        activation = tf.matmul(input_tensor,W)\n",
    "        print activation.get_shape()\n",
    "        activation = tf.reshape(activation,[-1,num_kernels,kernel_dim])\n",
    "        a1 = tf.expand_dims(activation, 3)\n",
    "        a2 = tf.transpose(activation, perm=[1,2,0])\n",
    "        a2 = tf.expand_dims(a2, 0)\n",
    "        abs_diff = tf.reduce_sum(tf.abs(a1 - a2), reduction_indices=[2])\n",
    "        expsum  = tf.reduce_sum(tf.exp(-abs_diff), reduction_indices=[2])\n",
    "        expsum = expsum + bias\n",
    "        print expsum.get_shape()\n",
    "        return tf.concat([input_tensor,expsum],axis=1)\n",
    "\n",
    "def gaussian_noise_layer(input_tensor, std=0.2):\n",
    "    noise = tf.random_normal(shape=tf.shape(input_tensor), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "    return input_tensor + noise\n",
    "\n",
    "def lrelu(x,alpha=0.2):\n",
    "    return tf.maximum(x, alpha*x)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def linear(input_tensor, input_dim, output_dim, name=None):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable(\"weights\", [input_dim, output_dim], initializer=tf.truncated_normal_initializer(stddev=math.sqrt(3.0 / (input_dim + output_dim))))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(input_tensor, weights) + bias \n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "def conv_2d(input_tensor, input_dim, output_dim, name=None):\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [5, 5,input_dim, output_dim], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.conv2d(input_tensor, kernel, strides=[1, 2, 2, 1],padding='SAME')\n",
    "        return conv+bias\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "def conv_2dtranspose(input_tensor, input_dim, output_shape,name=None):\n",
    "    output_dim=output_shape[-1]\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable(\"kernel\", [5, 5, output_dim, input_dim], initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        bias = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.nn.conv2d_transpose(input_tensor, kernel, output_shape=output_shape, strides=[1, 2, 2, 1],padding='SAME')\n",
    "        return deconv+bias\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "def batch_norm(input_tensor,name,is_train=True):\n",
    "    return tf.contrib.layers.batch_norm(input_tensor,decay=0.9, updates_collections=None, epsilon=1e-5, scale=True,    \n",
    "                                        is_training=is_train, scope=name)\n",
    "\n",
    "\n",
    "load_img_datagen = ImageDataGenerator(preprocessing_function = preprocessing)\n",
    "img_input = load_img_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "\n",
    "def generator(z):\n",
    "#    z = tf.placeholder(tf.float32, [None, 100], name='z')\n",
    "    l1=linear(input_tensor=z,name=\"g_lin\", input_dim=100, output_dim=1024*4*4)  \n",
    "    l2= tf.reshape(l1, [-1, 4, 4, 1024])\n",
    "    l3 = lrelu(batch_norm(input_tensor=l2,name=\"g_bn0\"))\n",
    "    print l3\n",
    "    #conv1\n",
    "    l4=conv_2dtranspose(input_tensor=l3,name=\"g_c2dt1\",input_dim=1024,output_shape=[batch_size,8,8,512])\n",
    "    l5=lrelu(batch_norm(input_tensor=l4,name=\"g_bn1\"))\n",
    "    print l5\n",
    "    #conv2\n",
    "    l6=conv_2dtranspose(input_tensor=l5,name=\"g_c2dt2\",input_dim=512,output_shape=[batch_size,16,16,256])\n",
    "    l7=lrelu(batch_norm(input_tensor=l6,name='g_bn2'))\n",
    "    print l7\n",
    "    #conv3\n",
    "    l8=conv_2dtranspose(input_tensor=l7,name='g_c2dt3',input_dim=256,output_shape=[batch_size,32,32,128])\n",
    "    l9=lrelu(batch_norm(input_tensor=l8,name='g_bn3'))\n",
    "    print l9\n",
    "    #conv4\n",
    "    l10=conv_2dtranspose(input_tensor=l9,name='g_c2dt4',input_dim=128,output_shape=[batch_size,64,64,3])\n",
    "    l11=tf.nn.tanh(l10)\n",
    "    print l11\n",
    "    return l11\n",
    "\n",
    "def discriminator(images, reuse=False, alpha=0.2):\n",
    "     with tf.variable_scope(\"discriminator\") as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        #naming of the layers is as per layer number    \n",
    "        #h0 conv2d no batch_norm\n",
    "        images = gaussian_noise_layer(images)\n",
    "        l1 = conv_2d(input_tensor=images, input_dim=3, output_dim= 64, name='d_c2d0')\n",
    "        l2 = lrelu(l1,alpha)\n",
    "\n",
    "        #h1 conv2d with batch_norm\n",
    "        l3 = conv_2d(input_tensor=l2, input_dim=64, output_dim=64*2, name='d_c2d1')\n",
    "        l4 = batch_norm(input_tensor=l3,name=\"d_bn1\")\n",
    "        l5 = lrelu(l4,alpha)\n",
    "\n",
    "        #h2 conv2d with batch_norm\n",
    "        l6 = conv_2d(input_tensor=l5, input_dim=64*2, output_dim=64*4, name='d_c2d2')\n",
    "        l7 = batch_norm(input_tensor=l6,name=\"d_bn2\")\n",
    "        l8 = lrelu(l7,alpha)\n",
    "\n",
    "        #h3 conv2d with batch_norm\n",
    "        l9 = conv_2d(input_tensor=l8, input_dim=64*4, output_dim=64*8, name='d_c2d3')\n",
    "        l10 = batch_norm(input_tensor=l9,name=\"d_bn3\")\n",
    "        l11 = lrelu(l10,alpha)\n",
    "\n",
    "        #h4 reshape and linear\n",
    "        l12 = tf.reshape(l11, [-1, 8192]) #l12 = tf.reshape(l11, [32, -1]) #l12 = tf.reshape(l11, [64, -1])\n",
    "        l13 = minibatch_discrimination(l12,name=\"d_mini\",num_kernels=100)\n",
    "        print l13.get_shape()\n",
    "        input_dim_linear = l13.get_shape().as_list()\n",
    "        l14 = linear(input_tensor=l13, input_dim=input_dim_linear[1], output_dim=1, name=\"d_lin4\")\n",
    "        print l14.get_shape().as_list()\n",
    "        #sigmoid\n",
    "        #minibatch discrimination layer\n",
    "\n",
    "        l15 = tf.nn.sigmoid(l14)\n",
    "        print l15\n",
    "        return l15, l14\n",
    "    \n",
    "z = tf.placeholder(tf.float32, [None, 100], name='z')\n",
    "G = generator(z)\n",
    "\n",
    "images = tf.placeholder(\n",
    "            tf.float32, [None] + image_shape, name='real_images')\n",
    "\n",
    "D1, D1_logits = discriminator(images, False, alpha)\n",
    "D2, D2_logits = discriminator(G, True, alpha)\n",
    "\n",
    "t_vars=tf.trainable_variables()\n",
    "discrim_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "gen_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "\n",
    "discrim_loss_real_img = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D1_logits, labels=tf.scalar_mul(0.9,tf.ones_like(D1_logits))))\n",
    "discrim_loss_fake_img = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_logits, labels=tf.zeros_like(D2_logits)))\n",
    "discrim_loss = discrim_loss_real_img + discrim_loss_fake_img\n",
    "gen_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=D2_logits, labels=tf.ones_like(D2_logits)))\n",
    "\n",
    "dopt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(discrim_loss, var_list=discrim_vars)\n",
    "gopt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)\n",
    "\n",
    "\n",
    "\n",
    "#new code starts here\n",
    "#create a saver to load the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def load(checkpoint_dir):\n",
    "    print(\" [*] Reading checkpoints...\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "isLoaded = load('models/')\n",
    "\n",
    "mask = tf.placeholder(tf.float32, [None] + image_shape, name='mask')\n",
    "imp_matrix = tf.placeholder(tf.float32, [None] + image_shape, name='imp_matrix')\n",
    "\n",
    "contextual_loss = tf.reduce_sum(\n",
    "    tf.contrib.layers.flatten(\n",
    "        tf.multiply(tf.abs(tf.multiply(tf.cast(mask,tf.float32), tf.cast(G,tf.float32)) - tf.multiply(tf.cast(mask,tf.float32), tf.cast(images, tf.float32))),tf.cast(imp_matrix, tf.float32))), 1)\n",
    "\n",
    "perceptual_loss = gen_loss\n",
    "complete_loss = contextual_loss + lambda_val*perceptual_loss\n",
    "grad_complete_loss = tf.gradients(complete_loss, z)\n",
    "\n",
    "#get input image y\n",
    "real_images=next(img_input)\n",
    "\n",
    "batch_images = np.array(real_images).astype(np.float32)\n",
    "\n",
    "img = (real_images[1,:,:,:] +1.)/2\n",
    "plt.imshow(img)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "config = {}\n",
    "config['maskType'] = 'center'\n",
    "config['learning_rate'] = 0.01\n",
    "config['momentum'] = 0.9\n",
    "\n",
    "\n",
    "#get mask M\n",
    "if config['maskType'] == 'random':\n",
    "    fraction_masked = 0.2\n",
    "    mask_ = np.ones(image_shape)\n",
    "    mask_[np.random.random(image_shape[:2]) < fraction_masked] = 0.0\n",
    "elif config['maskType'] == 'center':\n",
    "    scale = 0.25\n",
    "    #assert(scale <= 0.5)\n",
    "    mask_ = np.ones(image_shape)\n",
    "    sz = image_size\n",
    "    l = int(image_size*scale)\n",
    "    u = int(image_size*(1.0-scale))\n",
    "    mask_[l:u, l:u, :] = 0.0\n",
    "elif config['maskType'] == 'left':\n",
    "    mask_ = np.ones(image_shape)\n",
    "    c = image_size // 2\n",
    "    mask_[:,:c,:] = 0.0\n",
    "elif config['maskType'] == 'full':\n",
    "    mask_ = np.ones(image_shape)\n",
    "else:\n",
    "    assert(False)\n",
    "    \n",
    "def merge_images(image_batch, size):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    c = image_batch.shape[3]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1], c))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w,:] = im\n",
    "    return img\n",
    "\n",
    "#create the importance matrix\n",
    "\n",
    "a=np.ones((64,64))\n",
    "n=64\n",
    "for k in range(1,16):\n",
    "    for i in range(k,n-k):\n",
    "        for j in range(k,n-k):\n",
    "            a[i,j]+=1\n",
    "\n",
    "scale=0.25\n",
    "image_size=64\n",
    "sz = image_size\n",
    "l = int(image_size*scale)\n",
    "u = int(image_size*(1.0-scale))\n",
    "a[l:u, l:u] = 0.0\n",
    "\n",
    "non_zero_mean = np.sum(a)/(32*32)\n",
    "importance_matrix = a/32#non_zero_mean\n",
    "\n",
    "\n",
    "batch_mask = np.resize(mask_, [batch_size] + image_shape)\n",
    "imp_mask = np.resize(importance_matrix, [batch_size] + image_shape)\n",
    "zhats = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "\n",
    "vel = 0\n",
    "for i in xrange(5000):\n",
    "    fd = {\n",
    "        z: zhats,\n",
    "        imp_matrix: imp_mask,\n",
    "        mask: batch_mask,\n",
    "        images: batch_images,\n",
    "    }\n",
    "    run = [complete_loss, grad_complete_loss, G]\n",
    "    loss, g, G_imgs = sess.run(run, feed_dict=fd)\n",
    "    \n",
    "    if (i%500 is 0):\n",
    "        print \"loss in iteration: \" + str(i) + \" is: \" + str(np.mean(loss))\n",
    "\n",
    "    prev_vel = np.copy(vel)\n",
    "    vel = config['momentum']*vel - config['learning_rate']*g[0]\n",
    "    zhats += -config['momentum'] * prev_vel + (1+config['momentum'])*vel\n",
    "    zhats = np.clip(zhats, -1, 1)\n",
    "    \n",
    "created_images = (G_imgs + 1.)/2\n",
    "im = merge_images(created_images, [8,8])\n",
    "plt.imshow(im)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "masked_images = np.multiply(batch_images, batch_mask)\n",
    "input_images = (masked_images + 1.)/2\n",
    "im = merge_images(input_images, [8,8])\n",
    "plt.imshow(im)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "inv_mask_ = 1- mask_\n",
    "inv_batch_mask = np.resize(inv_mask_, [batch_size] + image_shape)\n",
    "inv_masked_images = np.multiply(batch_images, inv_batch_mask)\n",
    "\n",
    "inv_input_images = (inv_masked_images + 1.)/2\n",
    "im_ = merge_images(inv_input_images, [8,8])\n",
    "plt.imshow(im_)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "inv_batch_mask = np.resize(inv_mask_, [batch_size] + image_shape)\n",
    "inv_masked_images = np.multiply(G_imgs, inv_batch_mask)\n",
    "Recons_img = inv_masked_images + masked_images\n",
    "rec_images = (Recons_img + 1.)/2\n",
    "im_r = merge_images(rec_images, [8,8])\n",
    "plt.imshow(im_r)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
